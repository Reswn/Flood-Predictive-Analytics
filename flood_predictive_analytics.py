# -*- coding: utf-8 -*-
"""Flood_Predictive_Analytics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UapHmuwAopiW0KeP08QHQ8SsjVbDCpDD

# Predictive Analytics for Flood Risk Prediction

---

Reni Kartika Suwandi

renisuwandi1011@gmail.com

--- ---

# Deskripsi Proyek

### Latar Belakang
Banjir merupakan salah satu bencana alam paling sering terjadi di seluruh dunia, dan menyebabkan kerugian besar secara ekonomi, kerusakan infrastruktur, hingga korban jiwa. Menurut World Meteorological Organization (WMO) dan United Nations Office for Disaster Risk Reduction (UNDRR), banjir menyumbang lebih dari 40% dari seluruh kejadian bencana hidrometeorologi setiap tahun secara global. Dengan meningkatnya variabilitas iklim dan perubahan tata guna lahan, risiko banjir semakin sulit diprediksi secara manual.

Sebagai respons terhadap tantangan ini, pemanfaatan teknologi data science dan machine learning dapat membantu dalam membangun sistem prediksi yang mampu mengidentifikasi kemungkinan terjadinya banjir berdasarkan data historis dan lingkungan. Proyek ini bertujuan untuk mengembangkan model prediktif menggunakan beberapa algoritma machine learning dan mengevaluasi performanya secara komparatif.

## 1. Import Library yang Dibutuhkan
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report, roc_curve
from scipy.stats import skew, kurtosis
import kagglehub
from kagglehub import KaggleDatasetAdapter
import zipfile
import os


# Model yang akan digunakan
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

"""## 2. Data Understanding

### 2.1 Data Loading

#### **Informasi Dataset**

| **Informasi**           | **Detail**                                                                 |
|------------------------|-----------------------------------------------------------------------------|
| **Nama Dataset**        | Flood Prediction Dataset                                                   |
| **Pembuat**             | Naiya Khalid                                                               |
| **Platform**            | [Kaggle](https://www.kaggle.com/datasets/naiyakhalid/flood-prediction-dataset) |
| **Tahun Pembuatan**     | Sekitar 2024 *(berdasarkan waktu unggahan terakhir)*                       |
| **Deskripsi Asal Data** | Tidak disebutkan secara eksplisit                                          |
| **Sumber Data**         | Tidak dijelaskan                                                           |
| **Lisensi**             | Tidak tercantum secara jelas di halaman dataset                            |
| **Fitur Dataset**       | 22 fitur input + 1 label target (`FloodProbability`)                       |
| **Tujuan Dataset**      | Prediksi kemungkinan banjir berdasarkan faktor-faktor lingkungan dan sosial|

### **Load Dataset**
"""

# Download dataset dari KaggleHub
path = kagglehub.dataset_download("naiyakhalid/flood-prediction-dataset")
print("Path to dataset files:", path)

# Cek isi folder (opsional untuk memastikan nama file)
print("File dalam folder:", os.listdir(path))

# Gunakan nama file CSV yang benar sesuai dataset
csv_file = os.path.join(path, "flood.csv")

# Baca dataset ke dalam DataFrame
df = pd.read_csv(csv_file)

# Tampilkan 5 baris pertama
print("5 Baris Pertama Dataset:")
print(df.head())

"""## **2.2 Exploratory Data Analysis (EDA)**

Exploratory Data Analysis (EDA) atau Analisis Data Eksploratif adalah tahap penting dalam proses analisis data dan machine learning, yang bertujuan untuk memahami struktur, karakteristik, dan pola dalam data sebelum membangun model.

### **2.2.1 Informasi Dasar Data**
"""

# Info dasar
print(" Shape:", df.shape)
print("\n First 5 rows:")
print(df.head())

"""**Insight**:  Terdapat 50.000 baris (observasi) dan 21 kolom (fitur)."""

# Tipe Data
print("\n Info:")
print(df.info())

"""**Insight**:
- Setiap kolom memiliki tepat 50.000 entri (non-null),
- 20 fitur bertipe int64 (bilangan bulat), mewakili skor atau indeks kondisi.
- 1 target FloodProbability bertipe float64
"""

# Statistik Deskriptif
print("\n Descriptive statistics:")
print(df.describe(include='all'))

"""**Insight**:
- Distribusi fitur	Umumnya simetris, mean ≈ median
- Nilai ekstrem	Ada potensi outlier di beberapa fitur (nilai max jauh di atas Q3)
- FloodProbability target	Distribusi sempit dan mendekati normal
- Penyebaran data	Mayoritas data terkonsentrasi di nilai tengah (3–6)
- Kebutuhan scaling	Ya, karena skala nilai fitur bervariasi

### **2.2.2 Data hilang**
"""

# Jumlah nilai kosong
print("\nMissing Values:")
missing = df.isnull().sum()
print(missing[missing > 0])

"""**Insight**: Tidak ada missing value (nilai hilang) dalam dataset

### **2.2.3 Data Duplikat**
"""

# Cek duplikat
print("\nDuplicate Rows:", df.duplicated().sum())
# Hapus jika ada
df.drop_duplicates(inplace=True)

"""**Insight**: Tidak ada (nilai duplicate) dalam dataset

2.2.3 Data Unik
"""

# Jumlah nilai unik per kolom
print("\nUnique Values per Column:")
for col in df.columns:
    print(f"{col}: {df[col].nunique()} unique values")

"""**Insight:**
- Sebagian besar fitur	17–19	Diskret, kemungkinan skala ordinal. Bisa digunakan dalam regresi & klasifikasi.

- FloodProbability	83	Target numerik kontinu → regresi.

- FloodLabel	2	Target kategorikal biner - klasifikasi.

- PoliticalFactors	11	Relatif rendah cek signifikansi/korelasi.

### **2.2.4 Distribusi Target Variabel**
"""

# Membuat plot Distribusi
plt.figure(figsize=(5,4))
sns.countplot(x='FloodProbability', data=df)
plt.title('Distribusi Target (FloodProbability)')
plt.xlabel('FloodProbability')
plt.ylabel('Jumlah')
plt.show()

# Rasio kelas
class_ratio = df['FloodProbability'].value_counts(normalize=True)
print("\nRasio Kelas:\n", class_ratio)

"""**Insight**:
- Kondisi dengan rasio kelas mendekati 0.5 memiliki probabilitas banjir tertinggi, meskipun nilainya masih kecil.

- Rasio kelas yang terlalu tinggi atau terlalu rendah menunjukkan risiko banjir yang hampir nihil.

### **2.2.4 Distribusi Fitur Numerik**
"""

# fitur numerik
num_cols = df.select_dtypes(include=np.number).columns.tolist()
num_cols.remove('FloodProbability')  # Kecuali target

# Histogram untuk semua fitur numerik
df[num_cols].hist(figsize=(15, 10), bins=30)
plt.suptitle('Distribusi Semua Fitur Numerik', fontsize=16)
plt.tight_layout()
plt.show()

"""**Insight:**  
- Sebagian besar fitur memiliki distribusi yang seragam dan terkonsentrasi pada nilai rendah, menunjukkan bahwa kondisi alam dan manusia di banyak lokasi masih relatif stabil atau tidak terlalu ekstrem.

- Faktor-faktor seperti `WetlandLoss` dan `Deforestation` tampaknya memiliki potensi dampak yang lebih besar dibandingkan dengan fitur lainnya, karena mereka memiliki variasi yang lebih luas.

### **2.2.5 Outlier dan Penaganan Outlier**
"""

# Cek Outlier
for col in num_cols:
    plt.figure(figsize=(6, 4))
    sns.boxplot(x=df[col])
    plt.title(f'Boxplot {col}')
    plt.show()

"""**Menangani outlier**
- Q1 (Kuartil 1): Nilai di bawah 25% data berada.
- Q3 (Kuartil 3): Nilai di bawah 75% data berada.
- Bersama-sama, Q1 dan Q3 membentuk rentang tengah data.
- IQR = Q3 - Q1 → mengukur sebaran data tengah (middle 50%), Ini digunakan untuk memahami variabilitas data dan mendeteksi nilai yang terlalu jauh dari pusat data.
"""

# Mengani Outlier
Q1 = df[col].quantile(0.25)
Q3 = df[col].quantile(0.75)
IQR = Q3 - Q1
df = df[(df[col] >= Q1 - 1.5 * IQR) & (df[col] <= Q3 + 1.5 * IQR)]

"""### **2.2.6 Korelasi Antar Variabel**"""

# Ukuran figure yang lebih besar, disesuaikan dengan jumlah fitur
plt.figure(figsize=(14, 10))

# Buat heatmap
sns.heatmap(
    df.corr(),
    annot=True,
    cmap='coolwarm',
    fmt=".2f",
    square=True,
    linewidths= 0.5,
    cbar_kws={"shrink": 0.8}
)

plt.title("Correlation Matrix antar Variabel", fontsize=14)
plt.xticks(rotation=45, ha='right')
plt.yticks(rotation=0)
plt.tight_layout()  # Biar label tidak terpotong
plt.show()

"""### **2.2.8 Perbandingan Statistik Fitur per Kelas**"""

# Mebuat plot perbandingan statistik fitur per kelas
for col in num_cols:
    plt.figure(figsize=(6,4))
    sns.kdeplot(data=df, x=col, hue="FloodProbability", fill=True, common_norm=False, palette='crest')
    plt.title(f'Distribusi {col} Berdasarkan FloodProbability')
    plt.show()

"""### **2.2.9 Skewness dan Kurtosis**"""

# Mengecheck Skewness dan Kurtosis
print("Skewness dan Kurtosis:")
for col in num_cols:
    print(f"{col}: Skew={skew(df[col]):.2f}, Kurtosis={kurtosis(df[col]):.2f}")

"""**Insight:**

**Skewness(Kemencengan Data)**

Hampir semua variabel memiliki skewness antara 0.43 – 0.47 → artinya distribusi mereka sedikit miring ke kanan (positif skew).

Ini menunjukkan bahwa:
- Mayoritas nilai-nilai pada fitur tersebut cenderung kecil, tapi ada beberapa nilai tinggi (ekstrem).
- Variabel-variabel ini memiliki sejumlah kecil kondisi ekstrem yang bisa memperbesar risiko banjir.
- PoliticalFactors satu-satunya variabel dengan skewness rendah (0.21) → mendekati simetris.

**Kurtosis(Ketajaman Distribusi)**
- Sebagian besar variabel memiliki kurtosis antara 0.13 – 0.30 → sedikit lebih tajam dari normal, tapi tidak ekstrem.
- PoliticalFactors satu-satunya variabel dengan kurtosis negatif (-0.42) → distribusinya lebih datar dari normal (lebih tersebar merata, tidak banyak outlier).
- Variabel-variabel lain menunjukkan adanya sedikit outlier, tapi tidak terlalu mencolok.

### **2.2.10 Feature Correlation dengan Target**
"""

# Mencari Korelasi Fitur Dengan Target
correlation_with_target = df.corr()['FloodProbability'].drop('FloodProbability')
print("\nKorelasi Fitur dengan FloodProbability:")
print(correlation_with_target.sort_values(ascending=False))

correlation_with_target.sort_values().plot(kind='barh', figsize=(8,6))
plt.title("Korelasi Fitur dengan FloodProbability")
plt.xlabel("Correlation")
plt.show()

"""**Insight:**

**Fitur Paling Berkorelasi dengan Banjir (Top 5):**
DeterioratingInfrastructure	0.2306
TopographyDrainage	0.2297
RiverManagement	0.2292
DamsQuality	0.2286
Watersheds	0.2286

Insight: Infrastruktur yang buruk, manajemen sungai, kualitas bendungan, dan kondisi topografi berkaitan dengan peningkatan risiko banjir. Artinya, faktor-faktor ini bisa menjadi fokus utama dalam pencegahan banjir.


**Fitur dengan Korelasi Relatif Rendah (Bottom 5):**
DrainageSystems	0.2180
CoastalVulnerability	0.2165
PoliticalFactors	0.2138

Insight: Faktor-faktor seperti politik atau kerentanan pesisir memiliki hubungan yang lebih lemah dengan probabilitas banjir dalam dataset ini. Bukan berarti tidak penting, tapi mungkin lebih kontekstual atau tidak linier.

## **3. Data Preparation**

### **3.1 Train-Test Split Data**
"""

# Binarisasi target dimana FloodProbability menjadi FloodLabel (0 atau 1)
df['FloodLabel'] = (df['FloodProbability'] > 0.5).astype(int)
# Split fitur dan label
X = df.drop(['FloodProbability', 'FloodLabel'], axis=1)
y = df['FloodLabel']

# Split data latih dan uji
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""### **3.2 Standarisasi**"""

# Standardisasi
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""## **4. Model Development**

### **4.1 Decision Tree**
"""

# Decision Tree
dtree = DecisionTreeClassifier()
dtree.fit(X_train, y_train)
y_pred_dtree = dtree.predict(X_test)
y_prob_dtree = dtree.predict_proba(X_test)[:, 1]

print("\nDecision Tree")
print("Classification Report:")
print(classification_report(y_test, y_pred_dtree))

acc_dtree = accuracy_score(y_test, y_pred_dtree)
auc_dtree = roc_auc_score(y_test, y_prob_dtree)

# Membuat Plot Decision Tree
plt.figure(figsize=(4,3))
sns.heatmap(confusion_matrix(y_test, y_pred_dtree), annot=True, fmt='d', cmap='Greens')
plt.title('Confusion Matrix - Decision Tree')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""### **4.2 SVC (Support Vector Classifier)**"""

# SVC
svm = SVC(probability=True)
svm.fit(X_train_scaled, y_train)
y_pred_svm = svm.predict(X_test_scaled)
y_prob_svm = svm.predict_proba(X_test_scaled)[:, 1]

print("\nSupport Vector Classifier")
print("Classification Report:")
print(classification_report(y_test, y_pred_svm))

acc_svm = accuracy_score(y_test, y_pred_svm)
auc_svm = roc_auc_score(y_test, y_prob_svm)

# Membuat Plot SVM
plt.figure(figsize=(4,3))
sns.heatmap(confusion_matrix(y_test, y_pred_svm), annot=True, fmt='d', cmap='Purples')
plt.title('Confusion Matrix - SVC')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""### **4.3 Random Forest**"""

# Random Forest
rf = RandomForestClassifier(n_estimators=100)
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)
y_prob_rf = rf.predict_proba(X_test)[:, 1]

print("\nRandom Forest")
print("Classification Report:")
print(classification_report(y_test, y_pred_rf))

acc_rf = accuracy_score(y_test, y_pred_rf)
auc_rf = roc_auc_score(y_test, y_prob_rf)

# Membuat Plot Random Forest
plt.figure(figsize=(4,3))
sns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True, fmt='d', cmap='Oranges')
plt.title('Confusion Matrix - Random Forest')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""## Perbandingan Setiap Model"""

results_df = pd.DataFrame([
    {'Model': 'Decision Tree', 'Accuracy': acc_dtree, 'AUC': auc_dtree},
    {'Model': 'Random Forest', 'Accuracy': acc_rf, 'AUC': auc_rf},
    {'Model': 'SVM', 'Accuracy': acc_svm, 'AUC': auc_svm}
]).sort_values(by='Accuracy', ascending=False)


print("\n=== Model Performance Comparison ===")
print(results_df)

# Visualisasi Accuracy dan AUC dengan barplot berdampingan
plt.figure(figsize=(10,6))
sns.set_style("whitegrid")

# Plot Accuracy
sns.barplot(x='Model', y='Accuracy', data=results_df, color='skyblue', label='Accuracy')

# Plot AUC dengan axis kedua
ax2 = plt.twinx()
sns.lineplot(x='Model', y='AUC', data=results_df, sort=False, marker='o', color='orange', label='AUC', ax=ax2)
ax2.set_ylim(0, 1)

plt.title('Model Performance Comparison: Accuracy & AUC')
plt.legend(loc='upper left')
ax2.legend(loc='upper right')
plt.show()

"""#### **Model Terbaik: Support Vector Machine (SVM)**

Alasan Mengapa SVM Terbaik:
1. Akurasi Tertinggi (99.13%)
Ini berarti bahwa 99.13% dari prediksi SVM terhadap data uji cocok dengan label yang sebenarnya. Ini jauh lebih tinggi dibanding Random Forest (89.69%) dan Decision Tree (68.94%).

2. AUC Tertinggi (0.9997)
AUC (Area Under Curve) mendekati 1 menunjukkan bahwa model SVM sangat baik dalam membedakan antara kelas banjir (1) dan tidak banjir (0). AUC setinggi ini menunjukkan performa yang nyaris sempurna.

3. Model yang Lebih General
SVM cenderung lebih stabil dan tidak mudah overfitting jika dibandingkan dengan Decision Tree. Bahkan ketika dibandingkan dengan Random Forest (yang juga merupakan ensemble dari banyak decision tree), SVM masih lebih unggul dalam dataset ini.



**Kesimpulan**
Model Support Vector Machine (SVM) merupakan model terbaik untuk klasifikasi kejadian banjir dalam studi ini karena memberikan hasil akurasi dan AUC tertinggi, serta menunjukkan kemampuan yang sangat baik dalam membedakan antara dua kelas secara konsisten. Hal ini menunjukkan bahwa SVM mampu menangkap pola yang paling relevan dalam data, bahkan ketika faktor penyebab banjir bersifat kompleks.
"""